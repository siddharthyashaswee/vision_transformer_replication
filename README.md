ViT base model replication based on paper : An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. See Table 3 for hyperparameter details.

Also contains training and testing using the pretrained weights of the torchvision library : https://pytorch.org/vision/stable/models/vision_transformer.html
vit_b_16 : Weights used are IMAGENET1K_V1(DEFAULT ) and IMAGENET1K_SWAG_LINEAR_V1
